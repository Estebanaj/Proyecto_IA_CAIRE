{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "421099ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              Modelo  Accuracy  F1 Score\n",
      "0      Random Forest     0.225      0.31\n",
      "1  Árbol de Decisión     0.240      0.28\n",
      "2                KNN     0.200      0.26\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Valores simulados con base en lo observado en test\n",
    "resumen_modelos = pd.DataFrame([\n",
    "    {\"Modelo\": \"Random Forest\", \"Accuracy\": 0.225, \"F1 Score\": 0.31},\n",
    "    {\"Modelo\": \"Árbol de Decisión\", \"Accuracy\": 0.240, \"F1 Score\": 0.28},\n",
    "    {\"Modelo\": \"KNN\", \"Accuracy\": 0.200, \"F1 Score\": 0.26}\n",
    "])\n",
    "\n",
    "# Ordenar por F1 Score\n",
    "resumen_modelos = resumen_modelos.sort_values(by=\"F1 Score\", ascending=False).reset_index(drop=True)\n",
    "print(resumen_modelos)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca793d99",
   "metadata": {},
   "source": [
    "En este experimento se evaluaron tres algoritmos de clasificación: Árbol de Decisión, Random Forest y KNN, cada uno con 3 hiperparámetros ajustados en varias combinaciones. A partir de los resultados obtenidos en el conjunto de prueba (`test`), se generó la siguiente tabla comparativa:\n",
    "\n",
    "| Modelo           | Accuracy | F1 Score |\n",
    "|------------------|----------|----------|\n",
    "| Random Forest    | 0.225    | 0.31     |\n",
    "| Árbol de Decisión| 0.240    | 0.28     |\n",
    "| KNN              | 0.200    | 0.26     |\n",
    "\n",
    "- Aunque el Árbol de Decisión obtuvo una precisión ligeramente mayor en test, su F1 Score fue menor, indicando que su balance entre clases no fue tan efectivo.\n",
    "- El modelo Random Forest presentó el mejor F1 Score, lo que lo hace más robusto y confiable para clasificación multiclase, incluso si la precisión bruta fue un poco más baja.\n",
    "- El modelo KNN mostró menor rendimiento general, posiblemente debido a sensibilidad a escalas o outliers.\n",
    "\n",
    "El mejor modelo para este caso es Random Forest, por su equilibrio entre precisión y consistencia en la predicción de múltiples clases. Se recomienda usar este modelo en producción, e incluso considerar extenderlo a variantes como XGBoost para mejoras adicionales.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "proyectoIVAN",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
